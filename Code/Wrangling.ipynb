{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries for data wrangling\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import os\n",
    "import dask.dataframe as dd\n",
    "import csv\n",
    "import importlib\n",
    "import html\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import psutil\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "#load function files\n",
    "import Functions \n",
    "from Functions import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(Functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data from scratch - Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter_id,id,screen_name,name,description,url,timestamp_utc,local_time,location,verified,protected,tweets,followers,friends,likes,lists,image,default_profile,default_profile_image,witheld_in_countries,witheld_scope\n",
      "\n",
      "3342215494,3342215494,titisanogo8,Titi sanogo,Je crois en DIEU et à mon travail j'y arriverai.....,,1435017944,2015-06-23T00:05:44,\"Ile-de-France, France\",0,0,6,44,733,91,0,https://pbs.twimg.com/profile_images/1249394390029742081/xuVolLn6_normal.jpg,1,0,,\n",
      "\n",
      "3115495713,3115495713,AndreDeybach,DEYBACH André,,,1427309108,2015-03-25T18:45:08,,0,0,0,1,40,0,0,https://pbs.twimg.com/profile_images/580803690757533697/pHNcCBLh_normal.jpg,1,0,,\n",
      "\n",
      "244075010,244075010,matttownley1985,Matt Townley,\"Hotelier, traveller, fan of all things hospitality, great food and fine wine! All views my own etc!!\",,1296220595,2011-01-28T13:16:35,\"Manchester, England\",0,1,2535,772,1264,1251,7,https://pbs.twimg.com/profile_images/928075998930681856/ZFXboKc3_normal.jpg,0,0,,\n",
      "\n",
      "2986463442,2986463442,alex_guevara90,Alex ,to all MI b**** what's up,,1421472910,2015-01-17T05:35:10,,0,0,12,8,118,172,0,https://pbs.twimg.com/profile_images/556324296038285313/Ev_NvKzl_normal.png,1,0,,\n",
      "\n",
      "1519279241858330625,1519279241858330625,PilotDad87,Matt,Pilot. dad. husband. Catholic. Recteq master. 100 stroke golfer.,,1651059383,2022-04-27T11:36:23,\"Greenville, NC\",0,0,43,14,137,2069,0,https://pbs.twimg.com/profile_images/1519286870198345729/0woOjJ1P_normal.jpg,1,0,,\n",
      "\n",
      "3784597275,3784597275,cathybvaju,catherine,,,1443292646,2015-09-26T18:37:26,,0,0,8,49,256,21,0,https://pbs.twimg.com/profile_images/647843953417580544/CRIPCDj7_normal.jpg,1,0,,\n",
      "\n",
      "891453482070413312,891453482070413312,s18nanakaly,𝒮𝒶𝓃𝓃𝒶𝓇 ᥫ᭡,\"\"\"𝖧𝖺𝗇𝖽𝗌 𝗁𝖺𝗏𝖾 𝗍𝗁𝖾𝗂𝗋 𝗈𝗐𝗇 𝖼𝗈𝗇𝗏𝖾𝗋𝗌𝖺𝗍𝗂𝗈𝗇 \"\" ོ⠀ ⠀⠀⠀ ོ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ོ⠀⠀⠀⠀⠀ོ⠀⠀⠀ ོ⠀ ⠀⠀\",,1501374047,2017-07-30T00:20:47,Erbil,0,1,84,11,55,1289,0,https://pbs.twimg.com/profile_images/1553861976614469632/3hogj-tl_normal.jpg,1,0,,\n",
      "\n",
      "738440598865088512,738440598865088512,isusername1,isfirst,,,1464892933,2016-06-02T18:42:13,,0,0,0,4,167,0,0,https://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png,1,1,,\n",
      "\n",
      "956867643998339074,956867643998339074,Wafaa20169665,Wafaa,💋😘☕💞😇,,1516969998,2018-01-26T12:33:18,\"Ain-Temouchent, Algérie\",0,0,0,2,111,0,0,https://pbs.twimg.com/profile_images/956869008610996224/r121pfIK_normal.jpg,1,0,,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#How is my data delimited?\n",
    "path = '/home/livtollanes/SocialMarkers'\n",
    "file = 'markers_followers_bios_2023-05-19.csv'\n",
    "\n",
    "\n",
    "\n",
    "def print_lines(path, file, start_line=0, end_line=10):\n",
    "    with open(f\"{path}/{file}\", 'r') as f:\n",
    "        for i in range(end_line):\n",
    "            line = f.readline()\n",
    "            if i >= start_line:\n",
    "                print(line)\n",
    "\n",
    "print_lines(path, file)\n",
    "\n",
    "\n",
    "#The data is comma delimited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Loading in one data set\n",
    "# path = '/home/livtollanes/SocialMarkers'\n",
    "# file = 'markers_followers_bios_2023-05-19.csv'\n",
    "\n",
    "# def load_file(path, file, req_cols):\n",
    "#     return pd.read_csv(f\"{path}/{file}\", delimiter=',', quotechar='\"', low_memory=False, usecols=req_cols)\n",
    "\n",
    "\n",
    "# req_cols = ['twitter_id', 'id', 'screen_name', 'description', 'location', 'tweets', 'followers', 'friends', 'likes', 'lists','timestamp_utc']\n",
    "\n",
    "# # dtypes = {\n",
    "# #     'twitter_id': 'int64',\n",
    "# #     'id': 'float64',\n",
    "# #     'screen_name': 'object',\n",
    "# #     'description': 'object',\n",
    "# #     'location': 'object',\n",
    "# #     'tweets': 'float64',\n",
    "# #     'followers': 'float64',\n",
    "# #     'friends': 'float64',\n",
    "# #     'witheld_in_countries': 'float64'\n",
    "# # }\n",
    "\n",
    "# df = load_file(path, file, req_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # How much memory available?\n",
    "# def get_available_memory():\n",
    "#     return psutil.virtual_memory().available\n",
    "\n",
    "# available_memory = get_available_memory()\n",
    "# print(f\"Available memory: {available_memory / (1024 * 1024 * 1024)} GB\")\n",
    "\n",
    "\n",
    "# # check size of loaded df and print \n",
    "# def get_df_memory_usage(df):\n",
    "#     return df.info(memory_usage='deep')\n",
    "\n",
    "# get_df_memory_usage(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()\n",
    "\n",
    "# #insopect min and max value of column friends with f string\n",
    "# # print(f\"Min friends: {df.friends.min()}\")\n",
    "# # print(f\"Max friends: {df.friends.max()}\")\n",
    "\n",
    "\n",
    "# #check for multiple lines per user\n",
    "# duplicates = df.duplicated(subset='twitter_id', keep=False)\n",
    "# print(f\"Number of duplicate rows: {duplicates.sum()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Filtering out irrelevant users based on follower count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this part, we want to remove users that don't follow enough brands. \n",
    "- This is to match the procedure of He and Tsvetkova (2023)\n",
    "- The purpose is to ensure we have enough information to generate SES estimates for users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,cursor,follower_id\n",
      "\n",
      "415859364,,1655336804831174657\n",
      "\n",
      "415859364,,1659648141497454593\n",
      "\n",
      "415859364,,1525534139478310915\n",
      "\n",
      "415859364,,1659648883209674764\n",
      "\n",
      "415859364,,1659648836594458626\n",
      "\n",
      "415859364,,881616301\n",
      "\n",
      "415859364,,1618696506424303637\n",
      "\n",
      "415859364,,1659647872202055692\n",
      "\n",
      "415859364,,1659647973637357568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#How is my data delimited?\n",
    "path = '/home/livtollanes/SocialMarkers'\n",
    "file = 'markers_followers_2023-05-19.csv'\n",
    "\n",
    "\n",
    "\n",
    "def print_lines(path, file, start_line=0, end_line=10):\n",
    "    with open(f\"{path}/{file}\", 'r') as f:\n",
    "        for i in range(end_line):\n",
    "            line = f.readline()\n",
    "            if i >= start_line:\n",
    "                print(line)\n",
    "\n",
    "print_lines(path, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what about the other dfs?\n",
    "path = '/home/livtollanes/SocialMarkers'\n",
    "file = 'markers_followers_2023-05-19.csv'\n",
    "\n",
    "\n",
    "\n",
    "def print_lines(path, file, start_line=0, end_line=10):\n",
    "    with open(f\"{path}/{file}\", 'r') as f:\n",
    "        for i in range(end_line):\n",
    "            line = f.readline()\n",
    "            if i >= start_line:\n",
    "                print(line)\n",
    "\n",
    "print_lines(path, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify the number of brands each unique follower follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do the keys in the dict match the unique IDs in the file?\n",
    "\n",
    "# # Load the data into a DataFrame\n",
    "# df = pd.read_csv('/home/livtollanes/SocialMarkers/markers_followers_2023-05-19.csv',dtype={'cursor': object})\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionary of [keys: follower_Id, Value: Brand_id]\n",
    "Without loading the data into python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of keys:follower_id and value: brands\n",
    "brands_per_follower = defaultdict(set)\n",
    "\n",
    "# Open the CSV file\n",
    "with open('/home/livtollanes/SocialMarkers/markers_followers_2023-05-19.csv', 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        # Add the brand id to the set of brands for this follower\n",
    "        brands_per_follower[row['follower_id']].add(row['id'])\n",
    "\n",
    "\n",
    "# Convert the sets to counts to see how many brands each follower follows\n",
    "brands_per_follower_count = {follower_id: len(brands) for follower_id, brands in brands_per_follower.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique values in the dictionary is 236.\n"
     ]
    }
   ],
   "source": [
    "#How many unique values (brands) are there in the dictionary?\n",
    "\n",
    "unique_values = set(value for values in brands_per_follower.values() for value in values)\n",
    "\n",
    "# The number of unique values is the length of the set\n",
    "num_unique_values = len(unique_values)\n",
    "\n",
    "print(f\"The number of unique values in the dictionary is {num_unique_values}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of keys in the dictionary is 70636295.\n"
     ]
    }
   ],
   "source": [
    "# How many keys (follower_id) are there in the dictionary?\n",
    "num_keys = len(brands_per_follower_count)\n",
    "\n",
    "print(f\"The number of keys in the dictionary is {num_keys}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1655336804831174657', 4)\n",
      "('1659648141497454593', 3)\n",
      "('1525534139478310915', 3)\n",
      "('1659648883209674764', 1)\n",
      "('1659648836594458626', 1)\n",
      "('881616301', 1)\n",
      "('1618696506424303637', 1)\n",
      "('1659647872202055692', 1)\n",
      "('1659647973637357568', 1)\n",
      "('1659647339697524736', 1)\n"
     ]
    }
   ],
   "source": [
    "#inspect first key value pairs \n",
    "# Get an iterator over the dictionary's items\n",
    "items = iter(brands_per_follower_count.items())\n",
    "\n",
    "# Get the first 5 items\n",
    "for _ in range(10):\n",
    "    print(next(items))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of keys that follow less than 5 IDs is 66693204, which is 94.42% of the total. Removing these leaves 5.58% of the data, or 3943091 users.\n"
     ]
    }
   ],
   "source": [
    "# How many users follow less than num_brands brands?\n",
    "num_brands = 5\n",
    "\n",
    "# How many users follow less than num_brands brands?\n",
    "# Assuming brands_per_follower_count is your dictionary\n",
    "count = sum(1 for value in brands_per_follower_count.values() if value < num_brands)\n",
    "\n",
    "# Calculate the percentage\n",
    "percentage = (count / len(brands_per_follower_count)) * 100\n",
    "\n",
    "# Calculate the percentage of the remaining data\n",
    "remaining_percentage = 100 - percentage\n",
    "\n",
    "# Calculate the number of remaining users\n",
    "remaining_users = len(brands_per_follower_count) - count\n",
    "\n",
    "print(f\"The number of keys that follow less than {num_brands} IDs is {count}, which is {percentage:.2f}% of the total. Removing these leaves {remaining_percentage:.2f}% of the data, or {remaining_users} users.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1543191014579617793', {'326359913', '88944305', '415859364', '38164846', '348379865'})\n",
      "('1257705208592756737', {'60659498', '326359913', '60054156', '415859364', '348379865', '44084633'})\n",
      "('1301293067945807877', {'554957168', '88944305', '21915474', '415859364', '44084633'})\n",
      "('1644463375231885315', {'60659498', '60054156', '16096416', '88944305', '415859364', '348379865', '44084633'})\n",
      "('1233001848006729729', {'112754792', '133663801', '40448264', '88944305', '83864876', '415859364', '33893706', '19976004', '47902100'})\n",
      "('1659583369536053248', {'60054156', '16096416', '415859364', '348379865', '44084633'})\n",
      "('835476283249287169', {'42497567', '537989713', '415859364', '16097522', '36383320'})\n",
      "('2768568386', {'554957168', '415859364', '348379865', '44084633', '18481641'})\n",
      "('1659538858864791552', {'554957168', '63142684', '61193820', '415859364', '348379865', '44084633'})\n",
      "('923959702089797633', {'25487201', '861574608', '415859364', '38164846', '348379865', '44084633'})\n"
     ]
    }
   ],
   "source": [
    "# excluding users that follow less than 5 brands in our full dict\n",
    "\n",
    "num_brands = 5\n",
    "\n",
    "# Filter the dictionary\n",
    "filtered_brands_per_follower = {follower_id: brands for follower_id, brands in brands_per_follower.items() if len(brands) >= num_brands}\n",
    "\n",
    "#inspect first key value pairs in filtered dict\n",
    "items = iter(filtered_brands_per_follower.items())\n",
    "\n",
    "# Get the first 5 items\n",
    "for _ in range(10):\n",
    "    print(next(items))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list for the relevant user \n",
    "# Save the list to a file\n",
    "with open('/home/livtollanes/NewData/followfive_filtered.pkl', 'wb') as f:\n",
    "    pickle.dump(filtered_brands_per_follower, f)\n",
    "\n",
    "\n",
    "#load the pickle list from file\n",
    "# with open('/path/to/your/directory/followers_filtered.pkl', 'rb') as f:\n",
    "#     followers_filtered = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other filterings to do\n",
    "- sent at least 100 tweets\n",
    "- have at least 25 followers\n",
    "- sent at least five tweets in the first few months of the year the data was collected (maybe not relevant for this data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "10.1thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
