{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import sys\n",
    "import html\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "# Third-party library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import dask.dataframe as dd\n",
    "import psutil\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Local application/library specific imports\n",
    "import utils\n",
    "from utils import *\n",
    "\n",
    "\n",
    "\n",
    "from unidecode import unidecode\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # How much memory available?\n",
    "# def get_available_memory():\n",
    "#     return psutil.virtual_memory().available\n",
    "\n",
    "# available_memory = get_available_memory()\n",
    "# print(f\"Available memory: {available_memory / (1024 * 1024 * 1024)} GB\")\n",
    "\n",
    "\n",
    "# # check size of loaded df and print \n",
    "# def get_df_memory_usage(df):\n",
    "#     return df.info(memory_usage='deep')\n",
    "\n",
    "# get_df_memory_usage(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Filtering french brands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll aim to select only the french brands. \n",
    "- One approach is to use language detection. Via the gcd3 library (?)\n",
    "- Another approach could be to look at location\n",
    "\n",
    "\n",
    "Plan:\n",
    "- Load the df of the brands and their bios. \n",
    "- Filter\n",
    "- Now, filter the reduced follower df based on these final french brands\n",
    "\n",
    "- are all users now french ? (look at combination of language and location - potentially drop those that does not have any usable indicator)\n",
    "\n",
    "\n",
    "- Might need to manually inspect these later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter_id,id,screen_name,name,description,url,timestamp_utc,local_time,location,verified,protected,tweets,followers,friends,likes,lists,image,default_profile,default_profile_image,witheld_in_countries,witheld_scope\n",
      "\n",
      "3342215494,3342215494,titisanogo8,Titi sanogo,Je crois en DIEU et à mon travail j'y arriverai.....,,1435017944,2015-06-23T00:05:44,\"Ile-de-France, France\",0,0,6,44,733,91,0,https://pbs.twimg.com/profile_images/1249394390029742081/xuVolLn6_normal.jpg,1,0,,\n",
      "\n",
      "3115495713,3115495713,AndreDeybach,DEYBACH André,,,1427309108,2015-03-25T18:45:08,,0,0,0,1,40,0,0,https://pbs.twimg.com/profile_images/580803690757533697/pHNcCBLh_normal.jpg,1,0,,\n",
      "\n",
      "244075010,244075010,matttownley1985,Matt Townley,\"Hotelier, traveller, fan of all things hospitality, great food and fine wine! All views my own etc!!\",,1296220595,2011-01-28T13:16:35,\"Manchester, England\",0,1,2535,772,1264,1251,7,https://pbs.twimg.com/profile_images/928075998930681856/ZFXboKc3_normal.jpg,0,0,,\n",
      "\n",
      "2986463442,2986463442,alex_guevara90,Alex ,to all MI b**** what's up,,1421472910,2015-01-17T05:35:10,,0,0,12,8,118,172,0,https://pbs.twimg.com/profile_images/556324296038285313/Ev_NvKzl_normal.png,1,0,,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#reload(utils)\n",
    "importlib.reload(utils)\n",
    "\n",
    "#How is my data delimited?\n",
    "path = '/home/livtollanes/SocialMarkers'\n",
    "file = 'markers_followers_bios_2023-05-19.csv'\n",
    "\n",
    "utils.print_lines(path, file, 0,5)\n",
    "\n",
    "#The data is comma delimited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lod the markers_bios_2023-05-19.csv file\n",
    "path = '/home/livtollanes/SocialMarkers'\n",
    "file = 'markers_bios_2023-05-19.csv'\n",
    "\n",
    "req_cols = ['twitter_name', 'id', 'screen_name', 'description', 'location', 'tweets', 'followers', 'friends', 'likes', 'lists','timestamp_utc']\n",
    "\n",
    "dtypes = {'twitter_name':'object', \n",
    "          'id': 'float64',\n",
    "          'screen_name': 'object', \n",
    "          'description': 'object',\n",
    "          'location': 'object',\n",
    "          'tweets': 'float64',\n",
    "          'followers': 'float64',\n",
    "          'friends': 'float64',\n",
    "          'likes': 'float64',\n",
    "          'lists': 'float64',\n",
    "          'timestamp_utc': 'float64'}\n",
    "\n",
    "dfm = utils.fileloader(path, file, req_cols, dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in dfm_french: 142\n",
      "Number of rows in dfm_other: 95\n"
     ]
    }
   ],
   "source": [
    "# Remove emojis, weird font, and detect language in descriptions\n",
    "importlib.reload(utils)\n",
    "\n",
    "# First, process the descriptions in the DataFrame\n",
    "dfm = utils.process_description(dfm)\n",
    "\n",
    "# Then, split the DataFrame by language\n",
    "dfm_french, dfm_other = utils.split_by_language(dfm, 'fr')\n",
    "\n",
    "# Finally, print information about the resulting DataFrames\n",
    "utils.print_df_info(dfm_french, 'dfm_french')\n",
    "utils.print_df_info(dfm_other, 'dfm_other')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual inspection - did we miss any brands that are french?\n",
    "- This part was done by inspecting the data frame and looking up brands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The brands that were incorrectly detected as non french:\n",
    "\n",
    "- 21: Lafuma_France\n",
    "- 30: CarrefourFrance\n",
    "- 36: CasinoEnseigne\n",
    "- 37: Supermarche_G20\n",
    "- 38: VogueFrance\n",
    "- 39: FigaroMagazine\n",
    "- 41: LeMediaTv\n",
    "- 48: BFMTV\n",
    "- 92: TeleLoisirs\n",
    "- 94: ParisMatch\n",
    "- 96: Telerama\n",
    "- 101: EntMagazine\n",
    "- 106: OnzeMondial\n",
    "- 113: GQ_France\n",
    "- 119: LEXPRESS\n",
    "- 121: courrrierinter\n",
    "- 124: RCLens\n",
    "- 128: OL\n",
    "- 129: ognice\n",
    "- 131: StadeDeReims\n",
    "- 133: MontpellierHSC\n",
    "- 135: RCSA\n",
    "- 171: HECParis\n",
    "- 178: SciencesPo\n",
    "- 181: Univbordeaux\n",
    "- 182: UnivLyon1\n",
    "- 199: UniversiteCergy\n",
    "- 202: centralesupelec\n",
    "- 208: ENSAEparis\n",
    "- 215: esdes_BS\n",
    "- 221: LaCoudouliere\n",
    "- 226: LyceeProTissie\n",
    "- 227: PSVLaTournelle\n",
    "- 230: Decathlon\n",
    "- 231: Darty_Officiel\n",
    "- 233: Fnac\n",
    "- 236: AmazonFrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a column with the correct, manually identified, language\n",
    "# List of index numbers to change\n",
    "indices_to_change = [21, 30, 36, 37, 38, 39, 41, 48, 92, 94, 96, 101, 106, 113, 119, 121, 124, 128, 129, 131, 133, 135, 171, 178, 181, 182, 199, 202, 208, 215, 221, 226, 227, 230, 231, 233, 236]\n",
    "\n",
    "dfm_other = dfm_other.copy()\n",
    "dfm_other['corrected_language_country'] = ''\n",
    "dfm_other.loc[indices_to_change, 'corrected_language_country'] = 'fr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adding the identified rows to the french df\n",
    "# Filter the rows where 'corrected_language_country' is 'fr'\n",
    "selected_rows = dfm_other[dfm_other['corrected_language_country'] == 'fr']\n",
    "\n",
    "# Add these rows to dfm_country\n",
    "dfm_french = pd.concat([dfm_french, selected_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the french brands to a csv file iin path /home/livtollanes/NewData\n",
    "path = '/home/livtollanes/NewData'\n",
    "\n",
    "# Write dfm_french to a CSV file\n",
    "dfm_french.to_csv(f'{path}/french_brands.csv', index=False)\n",
    "\n",
    "# Write dfm_other to a CSV file\n",
    "dfm_other.to_csv(f'{path}/other_brands.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filtering out irrelevant users "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this part, we want to remove users that don't follow enough brands. \n",
    "- This is to match the procedure of He and Tsvetkova (2023)\n",
    "- The purpose is to ensure we have enough information to generate SES estimates for users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,cursor,follower_id\n",
      "\n",
      "415859364,,1655336804831174657\n",
      "\n",
      "415859364,,1659648141497454593\n",
      "\n",
      "415859364,,1525534139478310915\n",
      "\n",
      "415859364,,1659648883209674764\n",
      "\n",
      "415859364,,1659648836594458626\n",
      "\n",
      "415859364,,881616301\n",
      "\n",
      "415859364,,1618696506424303637\n",
      "\n",
      "415859364,,1659647872202055692\n",
      "\n",
      "415859364,,1659647973637357568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Take a look at the data (Of the markers and their followers)\n",
    "# path = '/home/livtollanes/SocialMarkers'\n",
    "# file = 'markers_followers_2023-05-19.csv'\n",
    "\n",
    "\n",
    "# def print_lines(path, file, start_line=0, end_line=10):\n",
    "#     with open(f\"{path}/{file}\", 'r') as f:\n",
    "#         for i in range(end_line):\n",
    "#             line = f.readline()\n",
    "#             if i >= start_line:\n",
    "#                 print(line)\n",
    "\n",
    "# print_lines(path, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify the number of brands each unique follower follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionary of [keys: follower_Id, Value: Brand_id]\n",
    "Without loading the data into python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of keys:follower_id and value: brands\n",
    "brands_per_follower = defaultdict(set)\n",
    "\n",
    "# Open the CSV file\n",
    "with open('/home/livtollanes/SocialMarkers/markers_followers_2023-05-19.csv', 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        # Add the brand id to the set of brands for this follower\n",
    "        brands_per_follower[row['follower_id']].add(row['id'])\n",
    "\n",
    "\n",
    "# Convert the sets to counts to see how many brands each follower follows\n",
    "brands_per_follower_count = {follower_id: len(brands) for follower_id, brands in brands_per_follower.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique values in the dictionary is 236.\n",
      "The number of keys in the dictionary is 70636295.\n",
      "First 5 items in the dictionary:\n",
      "('1655336804831174657', {'44084633', '23114836', '415859364', '21915474'})\n",
      "('1659648141497454593', {'348379865', '44084633', '415859364'})\n",
      "('1525534139478310915', {'348379865', '44084633', '415859364'})\n",
      "('1659648883209674764', {'415859364'})\n",
      "('1659648836594458626', {'415859364'})\n"
     ]
    }
   ],
   "source": [
    "#How many unique values (brands) are there in the dictionary?\n",
    "\n",
    "utils.inspect_dict(brands_per_follower, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of keys that follow less than 5 IDs is 66693204, which is 94.42% of the total. Removing these leaves 5.58% of the data, or 3943091 users.\n"
     ]
    }
   ],
   "source": [
    "# How many users follow less than num_brands brands?\n",
    "num_brands = 5\n",
    "\n",
    "# How many users follow less than num_brands brands?\n",
    "# Assuming brands_per_follower_count is your dictionary\n",
    "count = sum(1 for value in brands_per_follower_count.values() if value < num_brands)\n",
    "\n",
    "# Calculate the percentage\n",
    "percentage = (count / len(brands_per_follower_count)) * 100\n",
    "\n",
    "# Calculate the percentage of the remaining data\n",
    "remaining_percentage = 100 - percentage\n",
    "\n",
    "# Calculate the number of remaining users\n",
    "remaining_users = len(brands_per_follower_count) - count\n",
    "\n",
    "print(f\"The number of keys that follow less than {num_brands} IDs is {count}, which is {percentage:.2f}% of the total. Removing these leaves {remaining_percentage:.2f}% of the data, or {remaining_users} users.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1543191014579617793', {'415859364', '326359913', '88944305', '348379865', '38164846'})\n",
      "('1257705208592756737', {'60659498', '326359913', '44084633', '348379865', '60054156', '415859364'})\n",
      "('1301293067945807877', {'554957168', '88944305', '21915474', '44084633', '415859364'})\n",
      "('1644463375231885315', {'60659498', '88944305', '16096416', '44084633', '348379865', '60054156', '415859364'})\n",
      "('1233001848006729729', {'40448264', '83864876', '112754792', '33893706', '19976004', '88944305', '47902100', '133663801', '415859364'})\n"
     ]
    }
   ],
   "source": [
    "# excluding users that follow less than 5 brands in our full dict\n",
    "\n",
    "num_brands = 5\n",
    "\n",
    "# Filter the dictionary\n",
    "filtered_brands_per_follower = {follower_id: brands for follower_id, brands in brands_per_follower.items() if len(brands) >= num_brands}\n",
    "\n",
    "#inspect first key value pairs in filtered dict\n",
    "items = iter(filtered_brands_per_follower.items())\n",
    "\n",
    "# Get the first 5 items\n",
    "for _ in range(5):\n",
    "    print(next(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the list of users that followe more than five brands to a .pkl file\n",
    "with open('/home/livtollanes/NewData/followfive_filtered.pkl', 'wb') as f:\n",
    "    pickle.dump(filtered_brands_per_follower, f)\n",
    "\n",
    "\n",
    "#load the pickle list from file\n",
    "# with open('/path/to/your/directory/followers_filtered.pkl', 'rb') as f:\n",
    "#     followers_filtered = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, filter the follower df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Loading in one data set\n",
    "path = '/home/livtollanes/SocialMarkers'\n",
    "file = 'markers_followers_bios_2023-05-19.csv'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "req_cols = ['twitter_id', 'id', 'screen_name', 'description', 'location', 'tweets', 'followers', 'friends', 'likes', 'lists','timestamp_utc']\n",
    "\n",
    "dtypes = {\n",
    "    'twitter_id': 'int64',\n",
    "    'id': 'float64',\n",
    "    'screen_name': 'object',\n",
    "    'description': 'object',\n",
    "    'location': 'object',\n",
    "    'tweets': 'float64',\n",
    "    'followers': 'float64',\n",
    "    'friends': 'float64',\n",
    "    'witheld_in_countries': 'float64'\n",
    "}\n",
    "\n",
    "df = utils.fileloader(path, file, req_cols, dtypes)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the dictionary from the .pkl file\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/livtollanes/NewData/followfive_filtered.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 3\u001b[0m     followers_dict \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#make a list of the keys in the dictionary\u001b[39;00m\n\u001b[1;32m      6\u001b[0m followers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(followers_dict\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the dictionary from the .pkl file\n",
    "with open('/home/livtollanes/NewData/followfive_filtered.pkl', 'rb') as f:\n",
    "    followers_dict = pickle.load(f)\n",
    "    \n",
    "#make a list of the keys in the dictionary\n",
    "followers = list(followers_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1543191014579617793: {'415859364', '326359913', '88944305', '348379865', '38164846'}\n",
      "1257705208592756737: {'60659498', '326359913', '44084633', '348379865', '60054156', '415859364'}\n",
      "1301293067945807877: {'554957168', '88944305', '21915474', '44084633', '415859364'}\n",
      "1644463375231885315: {'60659498', '88944305', '16096416', '44084633', '348379865', '60054156', '415859364'}\n",
      "1233001848006729729: {'40448264', '83864876', '112754792', '33893706', '19976004', '88944305', '47902100', '133663801', '415859364'}\n"
     ]
    }
   ],
   "source": [
    "# Convert the dictionary items to a list\n",
    "items = list(followers_dict.items())\n",
    "\n",
    "# Get the first few entries\n",
    "first_entries = items[:5]\n",
    "\n",
    "# Print the first few entries\n",
    "for key, value in first_entries:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   twitter_id            id      screen_name  \\\n",
      "44884750  1233001848006729729  1.233002e+18  OmarKHA95647383   \n",
      "\n",
      "                                description  timestamp_utc location  tweets  \\\n",
      "44884750  ‏‏كل أرض يرفع فيها الآذان هي وطني   1.582806e+09      NaN   248.0   \n",
      "\n",
      "          followers  friends   likes  lists  \n",
      "44884750      193.0   3862.0  4242.0    0.0  \n"
     ]
    }
   ],
   "source": [
    "# Search for 1233001848006729729 in 'twitter_id' column\n",
    "mask = df['twitter_id'] == 1233001848006729729\n",
    "\n",
    "# Use the mask to select the rows where 'twitter_id' is 1233001848006729729\n",
    "matching_rows = df[mask]\n",
    "\n",
    "# Print the matching rows\n",
    "print(matching_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            twitter_id            id    screen_name  \\\n",
      "0           3342215494  3.342215e+09    titisanogo8   \n",
      "1           3115495713  3.115496e+09   AndreDeybach   \n",
      "7   738440598865088512  7.384406e+17    isusername1   \n",
      "28           912721573  9.127216e+08     Armelrichy   \n",
      "35            30797693  3.079769e+07  AVMGDIGITALHD   \n",
      "\n",
      "                                          description  timestamp_utc  \\\n",
      "0   Je crois en DIEU et à mon travail j'y arrivera...   1.435018e+09   \n",
      "1                                                 NaN   1.427309e+09   \n",
      "7                                                 NaN   1.464893e+09   \n",
      "28                                                NaN   1.351526e+09   \n",
      "35  THE NEW DIGITAL STATION!!! \\nfollowed by @ROCN...   1.239593e+09   \n",
      "\n",
      "                 location   tweets  followers  friends  likes  lists  \n",
      "0   Ile-de-France, France      6.0       44.0    733.0   91.0    0.0  \n",
      "1                     NaN      0.0        1.0     40.0    0.0    0.0  \n",
      "7                     NaN      0.0        4.0    167.0    0.0    0.0  \n",
      "28                    NaN      0.0        2.0    168.0    0.0    0.0  \n",
      "35                    NaN  73584.0      777.0   1504.0  250.0   12.0  \n"
     ]
    }
   ],
   "source": [
    "# Convert the keys in followers_dict to integers\n",
    "follower_ids = [int(key) for key in followers_dict.keys()]\n",
    "\n",
    "# Filter the DataFrame to only include the rows where 'twitter_id' is in the follower_ids list\n",
    "filtered_df = df[df['twitter_id'].isin(follower_ids)]\n",
    "\n",
    "# Print the first few rows of the filtered DataFrame\n",
    "print(filtered_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 3943091\n",
      "Number of columns: 11\n"
     ]
    }
   ],
   "source": [
    "# Print the number of rows in the DataFrame\n",
    "print(f\"Number of rows: {filtered_df.shape[0]}\")\n",
    "print(f\"Number of columns: {filtered_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all users that have sent less than 100 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "#check the dtype ow tweets in filtered df\n",
    "print(filtered_df['tweets'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after removing all with less than 100 tweets: 1381356\n",
      "Number of rows removed: 2561735\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame to only include users with more than 100 tweets\n",
    "filtered_df2 = filtered_df[filtered_df['tweets'] > 99]\n",
    "\n",
    "#print the number of rows in the filtered df\n",
    "print(f\"Number of rows after removing all with less than 100 tweets: {filtered_df2.shape[0]}\")\n",
    "\n",
    "#Print how many rows were removed\n",
    "print(f\"Number of rows removed: {filtered_df.shape[0] - filtered_df2.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after removing all with less than 25 followers: 1192532\n",
      "Number of rows removed: 188824\n"
     ]
    }
   ],
   "source": [
    "#  Only include users with more than 25 followers\n",
    "filtered_df3 = filtered_df2[filtered_df2['followers'] > 24]\n",
    "\n",
    "# Print the number of rows in the filtered DataFrame   \n",
    "print(f\"Number of rows after removing all with less than 25 followers: {filtered_df3.shape[0]}\")\n",
    "\n",
    "# Print how many rows were removed\n",
    "print(f\"Number of rows removed: {filtered_df2.shape[0] - filtered_df3.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most recent timestamp: 1684644667.0\n",
      "Most recent datetime: 2023-05-21 04:51:07\n",
      "Oldest timestamp: 1153057347.0\n",
      "Oldest datetime: 2006-07-16 13:42:27\n"
     ]
    }
   ],
   "source": [
    "#Find the most recent timestamp\n",
    "most_recent_timestamp = filtered_df3['timestamp_utc'].max()\n",
    "print(f\"Most recent timestamp: {most_recent_timestamp}\")\n",
    "\n",
    "#convert the timestamp to a datetime object\n",
    "most_recent_datetime = datetime.fromtimestamp(most_recent_timestamp)\n",
    "print(f\"Most recent datetime: {most_recent_datetime}\")\n",
    "\n",
    "\n",
    "#Do the same for the oldest timestamp\n",
    "oldest_timestamp = filtered_df3['timestamp_utc'].min()\n",
    "print(f\"Oldest timestamp: {oldest_timestamp}\")\n",
    "\n",
    "#convert the timestamp to a datetime object\n",
    "oldest_datetime = datetime.fromtimestamp(oldest_timestamp)\n",
    "print(f\"Oldest datetime: {oldest_datetime}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now write the filtered_df3 to a csv file\n",
    "# filtered_df3.to_csv('/home/livtollanes/NewData/filtered_follower_bios_.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filterings\n",
    "- Follow at least five brands\n",
    "- sent at least 100 tweets\n",
    "- have at least 25 followers\n",
    "- sent at least five tweets in the first few months of the year the data was collected (maybe not relevant for this data - the twitter bios data does not contain the tweets. Only creation date for the profile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "10.1thesis",
   "language": "python",
   "name": "10.1thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
