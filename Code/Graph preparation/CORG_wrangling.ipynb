{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "\n",
    "# Third party imports\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import prince\n",
    "from networkx.algorithms import bipartite\n",
    "from matplotlib.patches import Patch\n",
    "import community as community_louvain\n",
    "from netgraph import Graph\n",
    "\n",
    "# Local application imports\n",
    "sys.path.insert(0, '../Utility files')\n",
    "from corg import DiscoverDimension, BenchmarkDimension\n",
    "import utils2\n",
    "from utils2 import *\n",
    "import ca_pipeline\n",
    "from ca_pipeline import PipelineCorAnalysis\n",
    "from matplotlib.ticker import FuncFormatter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a labeled subset to use in the CORG approach\n",
    "This part of the repository was performed in order to do a marker selection process that has not been written about in the thesis because it did not work. \n",
    "The aim was to label certain marers as high or low SES based on assumptions, and identify the dimension that best separated the classififed markers. The approach is the CORG-approach created by the FOCOS group:\n",
    "https://github.com/pedroramaciotti/CORG/blob/main/tutorial/CORG_quickstart.ipynb \n",
    "\n",
    "\n",
    "- Before doing the actual CORG analysis, I am creating a labelled version of the full edgelist. Markers are labeled as high or low SES based on expert knowledge. This is subsequently to be used as input in the CORG method for model validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty data frame to use for labeling\n",
    "\n",
    "\n",
    "# # load data\n",
    "# path = '/home/livtollanes/NewData/DataWrangling/french_edgelist_marker_threshold.csv'\n",
    "\n",
    "# req_cols = ['marker_id', 'follower_id', 'twitter_name','followers','french_followers', 'type', 'type2']\n",
    "# dtypes = {'marker_id': 'object',\n",
    "#           'follower_id': 'object',\n",
    "#           'twitter_name': 'object',\n",
    "#           'followers': 'int64',\n",
    "#           'french_followers': 'int64',\n",
    "#           'type': 'object',\n",
    "#           'type2': 'object'}\n",
    "\n",
    "\n",
    "# edgelist_CORG = pd.read_csv(path, usecols=req_cols, dtype=dtypes)\n",
    "\n",
    "# #Separate my data frame into dictionary of types\n",
    "# def create_dict(df, key_col, value_col):\n",
    "#     unique_df = df.drop_duplicates(subset=[key_col, value_col])\n",
    "#     return unique_df.groupby(key_col)[value_col].apply(list).to_dict()\n",
    "\n",
    "\n",
    "# df_dict = create_dict(edgelist_CORG, 'type', 'twitter_name')\n",
    "# df_dict2 = create_dict(edgelist_CORG, 'type2', 'twitter_name')\n",
    "\n",
    "\n",
    "# for key, value in df_dict.items():\n",
    "#     value = list(set(value))\n",
    "#     print(f\"Key: {key}\")\n",
    "#     print(f\"Value: {value}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# # Create a csv file to use for labeling \n",
    "# rows = []\n",
    "# for key, values in df_dict.items():\n",
    "#     for value in values:\n",
    "#         row = {'type': key, 'twitter_name': value, 'high': '', 'low': ''}\n",
    "#         rows.append(row)\n",
    "\n",
    "# # Now we write the rows to a CSV file\n",
    "# keys = ['type', 'twitter_name', 'high', 'low']\n",
    "\n",
    "# with open('/home/livtollanes/10.jan-thesis/labeldata/labeled_markers_empty.csv', 'w', newline='') as output_file:\n",
    "#     dict_writer = csv.DictWriter(output_file, keys)\n",
    "#     dict_writer.writeheader()\n",
    "#     dict_writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the empty df above was fille din externally in a google docs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load filled data\n",
    "# load data (this is the full list of markers together with the labels) 223 markers\n",
    "path = '/home/livtollanes/10.jan-thesis/labeldata/filled_labels_markers.csv'\n",
    "\n",
    "req_cols = ['type', 'twitter_name', 'high', 'low', 'other']\n",
    "dtypes = {'type': 'object',\n",
    "          'twitter_name': 'object',\n",
    "          'high': 'object',\n",
    "          'low': 'object',\n",
    "          'other': 'object'}\n",
    "\n",
    "labels_hl = pd.read_csv(path, usecols=req_cols, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#refomat the data\n",
    "# I put 0: low, 1: high, NA: other\n",
    "# Create the labeled marker df to input to the CORG method\n",
    "\n",
    "# Create a copy of labels_hl\n",
    "labels_CORG = labels_hl.copy()\n",
    "\n",
    "# Create 'SES' column\n",
    "labels_CORG['label'] = np.where(labels_CORG['high'] == '1', '1', \n",
    "                              np.where(labels_CORG['low'] == '1', '0', 'NA'))\n",
    "\n",
    "\n",
    "#0: low, 1: high, NA: other\n",
    "\n",
    "# Drop the rows where 'SES' is 'drop'\n",
    "labels_CORG = labels_CORG[labels_CORG['label'] != 'drop']\n",
    "\n",
    "# Keep only 'twitter_name' and 'SES' columns\n",
    "labels_CORG = labels_CORG[['twitter_name', 'type', 'label']]\n",
    "\n",
    "labels_CORG['label'].value_counts() # 22 H, 14 L. Looks correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load full marker edgelist data. All follower relationships\n",
    "path = '/home/livtollanes/NewData/DataWrangling/french_edgelist_marker_threshold.csv'\n",
    "\n",
    "req_cols = ['marker_id', 'follower_id', 'twitter_name','followers','french_followers', 'type', 'type2']\n",
    "dtypes = {'marker_id': 'object',\n",
    "          'follower_id': 'object',\n",
    "          'twitter_name': 'object',\n",
    "          'followers': 'int64',\n",
    "          'french_followers': 'int64',\n",
    "          'type': 'object',\n",
    "          'type2': 'object'}\n",
    "\n",
    "\n",
    "all = pd.read_csv(path, usecols=req_cols, dtype=dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_CORG_subset = labels_CORG[['twitter_name', 'label']]\n",
    "all_labeled = all.merge(labels_CORG_subset, how='left', on='twitter_name')\n",
    "\n",
    "#Save the labeled edgelist to csv in /home/livtollanes/NewData\n",
    "#all_labeled.to_csv('/home/livtollanes/NewData/DataWrangling/labeled_edgelist_hl.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "09.2thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
