{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1070120/474417774.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import prince\n",
    "import importlib\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "from matplotlib.patches import Patch\n",
    "import seaborn as sns\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from networkx.algorithms import bipartite\n",
    "\n",
    "\n",
    "import community as community_louvain\n",
    "from netgraph import Graph\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../Utility files')\n",
    "import corg\n",
    "from corg import DiscoverDimension\n",
    "import seaborn as sn\n",
    "from corg import BenchmarkDimension\n",
    "from corg import DiscoverDimension\n",
    "\n",
    "\n",
    "import utils2\n",
    "from utils2 import *\n",
    "import graphfunk\n",
    "from graphfunk import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See this link for setting up the facebook marketing API code:\n",
    "- https://github.com/carolcoimbra/facebook-ads/blob/master/example.ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Markers to Include?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I'll try to identify what markers that make sense to include in our analysis. \n",
    "- We identify the dimension that is best at classifying/separating markers of clear difference in SES.\n",
    "- We do this via the CORG method for different CA fits (varying the network to include or leave out certain markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The data loaded here contains a row for each follower relationship a brand has. It includes the original type column, as well as the changed column (condensed from 12 to 4 types.)\n",
    "- Additionally, it has been filtered to only include markers with more than 100 followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "path = '/home/livtollanes/NewData/french/french_edgelist_marker_threshold.csv'\n",
    "\n",
    "req_cols = ['marker_id', 'follower_id', 'twitter_name','followers','french_followers', 'type', 'type2']\n",
    "dtypes = {'marker_id': 'object',\n",
    "          'follower_id': 'object',\n",
    "          'twitter_name': 'object',\n",
    "          'followers': 'int64',\n",
    "          'french_followers': 'int64',\n",
    "          'type': 'object',\n",
    "          'type2': 'object'}\n",
    "\n",
    "\n",
    "edgelist_CORG = pd.read_csv(path, usecols=req_cols, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of high and low SES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marker_id</th>\n",
       "      <th>follower_id</th>\n",
       "      <th>twitter_name</th>\n",
       "      <th>type</th>\n",
       "      <th>followers</th>\n",
       "      <th>french_followers</th>\n",
       "      <th>type2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19976004</td>\n",
       "      <td>1193293102162862080</td>\n",
       "      <td>Mediapart</td>\n",
       "      <td>media</td>\n",
       "      <td>3079643</td>\n",
       "      <td>64182</td>\n",
       "      <td>information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19976004</td>\n",
       "      <td>2884619299</td>\n",
       "      <td>Mediapart</td>\n",
       "      <td>media</td>\n",
       "      <td>3079643</td>\n",
       "      <td>64182</td>\n",
       "      <td>information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19976004</td>\n",
       "      <td>782999494703054848</td>\n",
       "      <td>Mediapart</td>\n",
       "      <td>media</td>\n",
       "      <td>3079643</td>\n",
       "      <td>64182</td>\n",
       "      <td>information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19976004</td>\n",
       "      <td>124458686</td>\n",
       "      <td>Mediapart</td>\n",
       "      <td>media</td>\n",
       "      <td>3079643</td>\n",
       "      <td>64182</td>\n",
       "      <td>information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19976004</td>\n",
       "      <td>2960220189</td>\n",
       "      <td>Mediapart</td>\n",
       "      <td>media</td>\n",
       "      <td>3079643</td>\n",
       "      <td>64182</td>\n",
       "      <td>information</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marker_id          follower_id twitter_name   type  followers  \\\n",
       "0  19976004  1193293102162862080    Mediapart  media    3079643   \n",
       "1  19976004           2884619299    Mediapart  media    3079643   \n",
       "2  19976004   782999494703054848    Mediapart  media    3079643   \n",
       "3  19976004            124458686    Mediapart  media    3079643   \n",
       "4  19976004           2960220189    Mediapart  media    3079643   \n",
       "\n",
       "   french_followers        type2  \n",
       "0             64182  information  \n",
       "1             64182  information  \n",
       "2             64182  information  \n",
       "3             64182  information  \n",
       "4             64182  information  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edgelist_CORG.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64182"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edgelist_CORG['french_followers'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Within each of the 12 brand types, identify brands that are either high or low SES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in 'type': 12\n",
      "\n",
      "type = Lyc√©es professionels:\n",
      "  Min 'french_followers': 9\n",
      "  Max 'french_followers': 45\n",
      "\n",
      "type = chain restaurants:\n",
      "  Min 'french_followers': 121\n",
      "  Max 'french_followers': 5716\n",
      "\n",
      "type = clubs de football:\n",
      "  Min 'french_followers': 139\n",
      "  Max 'french_followers': 21482\n",
      "\n",
      "type = commerce:\n",
      "  Min 'french_followers': 171\n",
      "  Max 'french_followers': 16142\n",
      "\n",
      "type = ecoles de commerce:\n",
      "  Min 'french_followers': 358\n",
      "  Max 'french_followers': 4128\n",
      "\n",
      "type = grande distribution:\n",
      "  Min 'french_followers': 31\n",
      "  Max 'french_followers': 8662\n",
      "\n",
      "type = luxe vetements et malls:\n",
      "  Min 'french_followers': 2\n",
      "  Max 'french_followers': 9385\n",
      "\n",
      "type = magazine:\n",
      "  Min 'french_followers': 1\n",
      "  Max 'french_followers': 40800\n",
      "\n",
      "type = media:\n",
      "  Min 'french_followers': 132\n",
      "  Max 'french_followers': 64182\n",
      "\n",
      "type = party:\n",
      "  Min 'french_followers': 6\n",
      "  Max 'french_followers': 17275\n",
      "\n",
      "type = sport:\n",
      "  Min 'french_followers': 2\n",
      "  Max 'french_followers': 7885\n",
      "\n",
      "type = universities:\n",
      "  Min 'french_followers': 8\n",
      "  Max 'french_followers': 7970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "path = '/home/livtollanes/NewData/french/french_edgelist.csv'\n",
    "\n",
    "req_cols = ['marker_id', 'follower_id', 'twitter_name','followers','type']\n",
    "dtypes = {'marker_id': 'object',\n",
    "          'follower_id': 'object',\n",
    "          'twitter_name': 'object',\n",
    "          'followers': 'int64',\n",
    "          'type': 'object'}\n",
    "\n",
    "\n",
    "edgelist_old = pd.read_csv(path, usecols=req_cols, dtype=dtypes)\n",
    "\n",
    "\n",
    "edgelist_old['french_followers'] = edgelist_old.groupby('marker_id')['marker_id'].transform('size')\n",
    "\n",
    "utils2.check_types(edgelist_old, 'type', 'french_followers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just double checked. We have only 11 types in the newly loaded df. This is because all Lyc√©es Professionels in the french edgelist had less than 100 followers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edgelist_CORG['twitter_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate my data frame into dictionary of types\n",
    "def create_dict(df, key_col, value_col):\n",
    "    unique_df = df.drop_duplicates(subset=[key_col, value_col])\n",
    "    return unique_df.groupby(key_col)[value_col].apply(list).to_dict()\n",
    "\n",
    "\n",
    "df_dict = create_dict(edgelist_CORG, 'type', 'twitter_name')\n",
    "df_dict2 = create_dict(edgelist_CORG, 'type2', 'twitter_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: Lyc√©es professionels\n",
      "Value: ['PSVLaTournelle', 'lpovanicet', 'LaCoudouliere', 'GilbertLycee', 'VaubanLycee', 'LPHurleventBLF', 'LyceeProTissie']\n",
      "\n",
      "Key: chain restaurants\n",
      "Value: ['brioche_doree', 'pizzahutfr', 'bigmammagroup', 'QuickFrance_', 'KFCFrance', 'BurgerKingFR', 'McDonaldsFrance']\n",
      "\n",
      "Key: clubs de football\n",
      "Value: ['OM_Officiel', 'ClermontFoot', 'OL', 'estac_officiel', 'LOSC_EN', 'PSG_inside', 'ogcnice', 'ToulouseFC', 'StadeDeReims', 'ACAjaccio', 'AS_Monaco', 'RCSA', 'FCLorient', 'FCNantes', 'RCLens', 'AJA', 'AngersSCO', 'MontpellierHSC']\n",
      "\n",
      "Key: commerce\n",
      "Value: ['vinted', 'Darty_Officiel', 'Fnac', 'Decathlon', 'AmazonFrance', 'Cdiscount', 'rueducommerce', 'boulanger']\n",
      "\n",
      "Key: ecoles de commerce\n",
      "Value: ['SKEMA_BS', 'inseec_ge', 'essec', 'IESEG', 'esdes_BS', 'Psbeduparis', 'ESCP_bs', 'EDHEC_BSchool', 'EMLYON']\n",
      "\n",
      "Key: grande distribution\n",
      "Value: ['CasinoEnseignes', 'Supermarche_G20', 'CarrefourFrance', 'picardsurgeles', 'lidlfrance', 'AUCHAN_France', 'marksandspencer', 'intermarche', 'Monoprix', 'franprix', 'Leclerc']\n",
      "\n",
      "Key: luxe vetements et malls\n",
      "Value: ['LouisVuitton', 'Hermes_Paris', 'YSL', 'Westfield_FDH', 'Dior', 'hmfrance', 'VeuveClicquot', 'UNIQLO_France', 'Cartier', 'SHEIN_Official', 'CHANEL', 'ZARA', 'LancomeFR']\n",
      "\n",
      "Key: magazine\n",
      "Value: ['TerreSauvageMag', 'LeCycle1', 'EntMagazine', 'LEXPRESS', 'InvestirFr', 'OnzeMondial', 'lessportivesmag', 'Sante_Magazine', 'ParisMatch', 'sofoot', 'Madamefigaro', 'forbes_fr', 'courrierinter', 'HarvardBiz', 'pleine_vie', 'FortuneMagazine', 'velomagazine', 'Telerama', 'GQ_France', 'NotreTemps', 'moto_journal', 'Sciences_Avenir', 'monjardinmag', 'lesinrocks', 'femmeactuelle', 'TennisMagazine1', 'TeleLoisirs', 'Tele7', 'Tele2Semaines', 'Telestarmag', 'TVMAG', 'Cosmopolitan_fr', 'marieclaire_fr', 'MagAvantages']\n",
      "\n",
      "Key: media\n",
      "Value: ['LaTribune', 'le_gorafi', 'franceculture', 'TheatrumBelli', 'Europe1', 'Causeur', 'francebleu', 'Valeurs', 'Actu17', 'Reporterre', 'BFMTV', 'lopinion_fr', 'mdiplo', 'Lagazettefr', '24heuresactu', 'fipradio', 'VICEfr', 'lanouvellerep_', 'FigaroMagazine_', 'rtlgroup', 'Mediapart', 'france_soir', 'humanite_fr', 'AlterEco_', 'Journal_Palaces', 'VogueFrance', 'LeMediaTV', 'Franc_De_Souche']\n",
      "\n",
      "Key: party\n",
      "Value: ['Walwari1', 'EELV', 'nationalistesfr', 'RNational_off', 'Renaissance', 'Reconquete2022', 'ResistonsFrance', 'MoDem', 'UPR_Officiel', 'PACEEurope', 'UDMF_officiel', '_LesPatriotes', 'lesRepublicains', 'FranceInsoumise', 'RSouveraine', 'Nouvelle_Donne', 'PartiAnimaliste', 'partisocialiste', 'LutteOuvriere', 'NPA_officiel', 'RevPermanente', 'LesCentristes_', 'PartiRadicalG', 'VPF_France', 'DLF_Officiel', 'PCF']\n",
      "\n",
      "Key: sport\n",
      "Value: ['KappaFrance', 'Reebok', 'Nike', 'pumafootball', '_Fusalp', 'Converse', 'ripcurl_europe', 'Lacoste', 'ASICSFrance', 'Timberland', 'lecoqsportif', 'billabong1973', 'adidasFR', 'TheNorthFaceEU', 'Quiksilver', 'Lafuma_France', 'UnderArmour', 'lululemon', 'Timberland_EU', 'Gymshark', 'iloveellesse', 'Moncler']\n",
      "\n",
      "Key: universities\n",
      "Value: ['UnivParis8', 'UGrenobleAlpes', 'UnivLyon1', 'univ_lyon2', 'SorbonneParis1', 'univbordeaux', 'UnivAngers', 'Ecoledeschartes', 'Paris_Dauphine', 'Mines_Paris', 'UnivTours', 'cdf1530', 'Univ_Toulouse', 'Ecole_navale', 'Polytechnique', 'AgroParisTech', 'univbourgogne', 'UGustaveEiffel', 'UniversiteCergy', 'Univ_Orleans', 'universitereims', 'EcoledesPonts', 'unistra', 'ENS_ULM', 'UCAuvergne', 'sciencespo', 'univrouen', 'telecomparis', 'univamu', 'univ_spn', 'UPJV_Univ', 'HECParis', 'UnilimDSI', 'centralesupelec', 'UnivPoitiers', 'NantesUniv', 'ENSAEparis', 'EHESS_fr', 'Sorbonne_Univ_', 'AssasUniversite']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in df_dict.items():\n",
    "    value = list(set(value))\n",
    "    print(f\"Key: {key}\")\n",
    "    print(f\"Value: {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Create a csv file to use for labeling \n",
    "rows = []\n",
    "for key, values in df_dict.items():\n",
    "    for value in values:\n",
    "        row = {'type': key, 'twitter_name': value, 'high': '', 'low': ''}\n",
    "        rows.append(row)\n",
    "\n",
    "# Now we write the rows to a CSV file\n",
    "keys = ['type', 'twitter_name', 'high', 'low']\n",
    "\n",
    "with open('/home/livtollanes/10.jan-thesis/labeldata/labeled_markers.csv', 'w', newline='') as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that we're using reasoning to determine our validation set here is slightly flawed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/home/livtollanes/10.jan-thesis/labeldata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORG for assessing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corg\n",
    "from corg import DiscoverDimension\n",
    "import seaborn as sn\n",
    "from corg import BenchmarkDimension\n",
    "from corg import DiscoverDimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "09.2thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
