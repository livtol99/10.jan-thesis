{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import sys\n",
    "import html\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "# Third-party library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import dask.dataframe as dd\n",
    "import psutil\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Local application/library specific imports\n",
    "import utils\n",
    "from utils import *\n",
    "\n",
    "\n",
    "\n",
    "from unidecode import unidecode\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Filtering french brands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll aim to select only the french brands. \n",
    "- One approach is to use language detection. Via the gcd3 library (?)\n",
    "- Another approach could be to look at location\n",
    "\n",
    "\n",
    "Plan:\n",
    "- Load the df of the brands and their bios. \n",
    "- Filter\n",
    "- Now, filter the reduced follower df based on these final french brands\n",
    "\n",
    "- are all users now french ? (look at combination of language and location - potentially drop those that does not have any usable indicator)\n",
    "\n",
    "\n",
    "- Might need to manually inspect these later on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Load and rename markersIDs in markers_bios\n",
    "\n",
    "# load_path = '/home/livtollanes/SocialMarkers'\n",
    "# save_path = '/home/livtollanes/NewData'\n",
    "# file = 'markers_bios_2023-05-19.csv'\n",
    "\n",
    "\n",
    "# req_cols = ['twitter_name', 'id', 'screen_name', 'description', 'location', 'tweets', 'followers', 'friends', 'likes', 'lists','timestamp_utc']\n",
    "# dtypes = {'twitter_name':'object', \n",
    "#           'id': 'float64',\n",
    "#           'screen_name': 'object', \n",
    "#           'description': 'object',\n",
    "#           'location': 'object',\n",
    "#           'tweets': 'float64',\n",
    "#           'followers': 'float64',\n",
    "#           'friends': 'float64',\n",
    "#           'likes': 'float64',\n",
    "#           'lists': 'float64',\n",
    "#           'timestamp_utc': 'float64'}\n",
    "\n",
    "# new_column_names = {'id': 'marker_id'}\n",
    "\n",
    "# markers_bios = utils.load_and_rename(load_path, save_path, file, req_cols, dtypes, new_column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Load and rename markers followers\n",
    "# load_path = '/home/livtollanes/SocialMarkers'\n",
    "# save_path = '/home/livtollanes/NewData'\n",
    "# file = 'markers_followers_2023-05-19.csv'\n",
    "\n",
    "# req_cols = ['id', 'follower_id']\n",
    "# dtypes = {'id': 'float64',\n",
    "#           'follower_id': 'float64'}\n",
    "\n",
    "# new_column_names = {'id': 'marker_id'}\n",
    "\n",
    "# markers_followers = utils.load_and_rename(load_path, save_path, file, req_cols, dtypes, new_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Load and rename markers followers bios\n",
    "# load_path = '/home/livtollanes/SocialMarkers'\n",
    "# save_path = '/home/livtollanes/NewData'\n",
    "# file = 'markers_followers_bios_2023-05-19.csv'\n",
    "\n",
    "\n",
    "# req_cols = ['twitter_id', 'id', 'screen_name', 'description', 'location', 'tweets', 'followers', 'friends', 'likes', 'lists','timestamp_utc']\n",
    "\n",
    "# dtypes = {\n",
    "#     'twitter_id': 'float64',\n",
    "#     'id': 'float64',\n",
    "#     'screen_name': 'object',\n",
    "#     'description': 'object',\n",
    "#     'location': 'object',\n",
    "#     'tweets': 'float64',\n",
    "#     'followers': 'float64',\n",
    "#     'friends': 'float64',\n",
    "#     'witheld_in_countries': 'float64'\n",
    "# }\n",
    "\n",
    "# new_column_names = {'twitter_id': 'follower_id'}\n",
    "\n",
    "# follower_bios = utils.load_and_rename(load_path, save_path, file, req_cols, dtypes, new_column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply load the files, if renaming already has been done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Load marker bios\n",
    "# path = '/home/livtollanes/NewData'\n",
    "# file = 'markers_bios_2023-05-19.csv'\n",
    "# req_cols = ['twitter_name', 'marker_id', 'screen_name', 'description', 'location', 'tweets', 'followers', 'friends', 'likes', 'lists','timestamp_utc']\n",
    "\n",
    "# dtypes = {'twitter_name':'object', \n",
    "#           'marker_id': 'float64',\n",
    "#           'screen_name': 'object', \n",
    "#           'description': 'object',\n",
    "#           'location': 'object',\n",
    "#           'tweets': 'float64',\n",
    "#           'followers': 'float64',\n",
    "#           'friends': 'float64',\n",
    "#           'likes': 'float64',\n",
    "#           'lists': 'float64',\n",
    "#           'timestamp_utc': 'float64'}\n",
    "\n",
    "# markers_bios = utils.fileloader(path, file, req_cols, dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load marker followers\n",
    "load_path = '/home/livtollanes/NewData'\n",
    "file = 'markers_followers_2023-05-19.csv'\n",
    "\n",
    "req_cols = ['marker_id', 'follower_id']\n",
    "dtypes = {'marker_id': 'float64',\n",
    "          'follower_id': 'float64'}\n",
    "\n",
    "\n",
    "markers_followers = utils.fileloader(load_path, file, req_cols, dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load marker follower bios\n",
    "\n",
    "#Didn't work but the df is currently loaded in the notebook\n",
    "follower_bios.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload(utils)\n",
    "importlib.reload(utils)\n",
    "\n",
    "#How is my data delimited?\n",
    "path = '/home/livtollanes/NewData'\n",
    "file1 = 'markers_bios_2023-05-19.csv'\n",
    "file2 = 'markers_followers_2023-05-19.csv'\n",
    "file3 = 'markers_followers_bios_2023-05-19.csv'\n",
    "\n",
    "\n",
    "utils.print_lines(path, file1, 0,1)\n",
    "utils.print_lines(path, file2, 0,1)\n",
    "utils.print_lines(path, file3, 0,2)\n",
    "\n",
    "#The data is comma delimited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now filtering on language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove emojis, weird font, and detect language in descriptions\n",
    "\n",
    "# Process the descriptions in the DataFrame\n",
    "markers_bios = utils.process_description(markers_bios)\n",
    "\n",
    "# Split the DataFrame by language\n",
    "markers_bios_french, markers_bios_other = utils.split_by_language(markers_bios, 'fr')\n",
    "\n",
    "# Finally, print information about the resulting DataFrames\n",
    "utils.print_df_info(markers_bios_french, 'markers_bios')\n",
    "utils.print_df_info(markers_bios_other, 'markers_bios_other')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual inspection - did we miss any brands that are french?\n",
    "- This part was done by inspecting the data frame and looking up brands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The brands that were incorrectly detected as non french:\n",
    "\n",
    "- 21: Lafuma_France\n",
    "- 30: CarrefourFrance\n",
    "- 36: CasinoEnseigne\n",
    "- 37: Supermarche_G20\n",
    "- 38: VogueFrance\n",
    "- 39: FigaroMagazine\n",
    "- 41: LeMediaTv\n",
    "- 48: BFMTV\n",
    "- 92: TeleLoisirs\n",
    "- 94: ParisMatch\n",
    "- 96: Telerama\n",
    "- 101: EntMagazine\n",
    "- 106: OnzeMondial\n",
    "- 113: GQ_France\n",
    "- 119: LEXPRESS\n",
    "- 121: courrrierinter\n",
    "- 124: RCLens\n",
    "- 128: OL\n",
    "- 129: ognice\n",
    "- 131: StadeDeReims\n",
    "- 133: MontpellierHSC\n",
    "- 135: RCSA\n",
    "- 171: HECParis\n",
    "- 178: SciencesPo\n",
    "- 181: Univbordeaux\n",
    "- 182: UnivLyon1\n",
    "- 199: UniversiteCergy\n",
    "- 202: centralesupelec\n",
    "- 208: ENSAEparis\n",
    "- 215: esdes_BS\n",
    "- 221: LaCoudouliere\n",
    "- 226: LyceeProTissie\n",
    "- 227: PSVLaTournelle\n",
    "- 230: Decathlon\n",
    "- 231: Darty_Officiel\n",
    "- 233: Fnac\n",
    "- 236: AmazonFrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add extra brands that were incorrectly defined as non-french:\n",
    "indices_to_change = [21, 30, 36, 37, 38, 39, 41, 48, 92, 94, 96, 101, 106, 113, 119, 121, 124, 128, 129, 131, 133, 135, 171, 178, 181, 182, 199, 202, 208, 215, 221, 226, 227, 230, 231, 233, 236]\n",
    "\n",
    "#Add and save file\n",
    "path_tosave = '/home/livtollanes/NewData/workdata'\n",
    "utils.add_extrabrands(indices_to_change, markers_bios_other, markers_bios_french, path_tosave)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, in this section, we have been working with the bios of the markers. We deleted all rows that were from brands that were not french. The final output of this section includes two dfs: one for the french brands and one for other brands (only selected columns)\n",
    "\n",
    "In the next section, we will load the data with user bios and metadata. We will filter based on certain metrics, and also ignore all connections between followers and non french brands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Finding french brands and their followers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this part, we want to filter the data to only include french brands with 10 000 or more followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a look at the data (Of the markers and their followers)\n",
    "path = '/home/livtollanes/NewData/'\n",
    "file = 'markers_followers_2023-05-19.csv'\n",
    "\n",
    "\n",
    "def print_lines(path, file, start_line=0, end_line=5):\n",
    "    with open(f\"{path}/{file}\", 'r') as f:\n",
    "        for i in range(end_line):\n",
    "            line = f.readline()\n",
    "            if i >= start_line:\n",
    "                print(line)\n",
    "\n",
    "print_lines(path, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce markers_followers to only include followers of french markers, as found in markers_bios_french\n",
    "importlib.reload(utils)\n",
    "markers_followers_french = utils.streamline_ids(markers_followers, 'marker_id', markers_bios_french, 'marker_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered data\n",
    "markers_followers_french.to_csv('/home/livtollanes/NewData/workdata/markers_followers_french_2023-05-19.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, we have data for the french markers and their followers (markers_followers_french )\n",
    "- we also have a df with all french markers and their bios (markers_bios_french)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Followers per brand - only including those with 10 000 +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many followers are there per brand? - faster to read the csv file rather than directly using the df\n",
    "importlib.reload(utils)\n",
    "\n",
    "#Create a dict of keys: brands and values: number of followers\n",
    "filepath = '/home/livtollanes/NewData/workdata/markers_followers_french_2023-05-19.csv'\n",
    "followers_per_brand_count = utils.create_followers_per_brand_dict(filepath)\n",
    "\n",
    "# Filter the dictionary to only include brands with more or equal to 10,000 followers\n",
    "brands_10000_followers = {brand: followers for brand, followers in followers_per_brand_count.items() if followers > 9999}\n",
    "\n",
    "# Print the number of such brands\n",
    "print(len(brands_10000_followers))\n",
    "\n",
    "#Now, keeping only the marker_Ids in the two relevant dfs based on the brands_10000_followers\n",
    "markers_bios_french_10k = utils.streamline_ids_dict(markers_bios_french, 'marker_id', brands_10000_followers)\n",
    "markers_followers_french10k = utils.streamline_ids_dict(markers_followers_french, 'marker_id', brands_10000_followers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our french marker_follower data is filtered so that it only includes french brands with 10 000 followers or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Streamline the follower_bios to only include the followers of the 10k brands\n",
    "follower_bios_french10k = utils.streamline_ids(follower_bios, 'follower_id', markers_followers_french10k, 'follower_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the 'follower_id' column of the target DataFrame\n",
    "missing_values_in_target = follower_bios['follower_id'].isnull().sum()\n",
    "print(f\"Number of missing values in 'follower_id' column of target DataFrame: {missing_values_in_target}\")\n",
    "\n",
    "# Check for duplicate values in the 'follower_id' column of the target DataFrame\n",
    "duplicate_values_in_target = follower_bios['follower_id'].duplicated().sum()\n",
    "print(f\"Number of duplicate values in 'follower_id' column of target DataFrame: {duplicate_values_in_target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something is wrong in the bio data. after filtering to only include the ids that are in the markers_followers_french10k data, the target (bio data) becomes smaller. This must mean that some ids for which we have follower info on, do not exist in the bio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the three files to csv\n",
    "markers_bios_french_10k.to_csv('/home/livtollanes/NewData/workdata/step2/french_markers_bios_10k_2023-05-19.csv', index=False)\n",
    "markers_followers_french10k.to_csv('/home/livtollanes/NewData/workdata/step2/french_markers_followers_10k_2023-05-19.csv', index=False)\n",
    "follower_bios_french10k.to_csv('/home/livtollanes/NewData/workdata/step2/french_follower_bios_10k_2023-05-19.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #count the unique ids in french_marker_bios and in filtered_markers_followers\n",
    "# print(french_marker_bios['id'].nunique())\n",
    "# print(markers_followers['id'].nunique())\n",
    "# print(french_markers_followers['id'].nunique())\n",
    "\n",
    "# #print the unique ids that occur in french_marker_bios but not in filtered_markers_followers\n",
    "# print(set(french_marker_bios['id']) - set(french_markers_followers['id']))\n",
    "\n",
    "# # Get the unique ids that occur in dfm_french but not in filtered_markers_followers\n",
    "# missing_ids = set(french_marker_bios['id']) - set(filtered_markers_followers['id'])\n",
    "\n",
    "# # Filter french_marker_bios to only include rows with these ids\n",
    "# missing_brands = french_marker_bios[french_marker_bios['id'].isin(missing_ids)]\n",
    "\n",
    "# # Print the missing brands\n",
    "# print(missing_brands)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obs: For three brands, existing in the french brands bio df, there are no data in the marker_follower data. Must inspect later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Filtering users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now that we have the french brands with enough followers, we want to remove users that don't follow enough of these \n",
    "- This is to match the procedure of He and Tsvetkova (2023)\n",
    "- The purpose is to ensure we have enough information to generate SES estimates for users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionary of [keys: follower_Id, Value: Brand_id]\n",
    "Without loading the data into python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary of [keys:follower_id, values: brands] based on the link between french brands and their followers\n",
    "importlib.reload(utils)\n",
    "\n",
    "filepath = '/home/livtollanes/NewData/workdata/step2/french_markers_followers_10k_2023-05-19.csv'\n",
    "brands_per_follower, brands_per_follower_count = utils.create_brands_per_follower_dict(filepath)\n",
    "\n",
    "#How many unique values (brands) are there in the dictionary?\n",
    "\n",
    "utils.inspect_dict(brands_per_follower, 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many people follow less than five french brands? Remove these from the dictionary\n",
    "num_brands = 5\n",
    "num_items = 5\n",
    "filtered_brands_per_follower = utils.inspect_and_filter_followers(brands_per_follower, num_brands, num_items, remove=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter the follower bio file to only include the followers that follow at least 5 of the french brands with more than 10 000 followers\n",
    "importlib.reload(utils)\n",
    "follower_bios_french10k_5 = utils.streamline_ids_dict(follower_bios_french10k, 'follower_id', filtered_brands_per_follower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all users that have sent less than 100 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to only include users with more than 100 tweets\n",
    "follower_bios_french10k_5_100 = follower_bios_french10k_5[follower_bios_french10k_5['tweets'] > 99]\n",
    "\n",
    "#print the number of rows in the filtered df\n",
    "print(f\"Number of rows after removing all with less than 100 tweets: {follower_bios_french10k_5_100.shape[0]}\")\n",
    "\n",
    "#Print how many rows were Removed\n",
    "print(f\"Number of rows removed: {follower_bios_french10k_5.shape[0] - follower_bios_french10k_5_100.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Only include users with more than 25 followers\n",
    "follower_bios_french10k_5_100_25 = follower_bios_french10k_5_100[follower_bios_french10k_5_100['followers'] > 24]\n",
    "\n",
    "# Print the number of rows in the filtered DataFrame   \n",
    "print(f\"Number of rows after removing all with less than 25 followers: {follower_bios_french10k_5_100_25.shape[0]}\")\n",
    "\n",
    "# Print how many rows were removed\n",
    "print(f\"Number of rows removed: {follower_bios_french10k_5_100.shape[0] - follower_bios_french10k_5_100_25.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#streamline the ids between follower_bios_french10k_5_100_25 and markers_followers_french10k\n",
    "importlib.reload(utils)\n",
    "markers_follower_french_10_5_100_25 = utils.streamline_ids(markers_followers_french10k,'follower_id', follower_bios_french10k_5_100_25 , 'follower_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now write the filtered_df3 to a csv file\n",
    "follower_bios_french10k_5_100_25.to_csv('/home/livtollanes/NewData/workdata/step2/step3/follower_bios_french10k_5_100_25.csv', index=False)\n",
    "markers_follower_french_10_5_100_25.to_csv('/home/livtollanes/NewData/workdata/step2/step3/markers_follower_french_10_5_100_25.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filterings so far\n",
    "- Users that follow french brands with 10 000 or more followers\n",
    "- Users that follow at least five brands\n",
    "- Have sent at least 100 tweets\n",
    "- Have at least 25 followers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filters I have not conducted\n",
    "- Filters based on user location or language\n",
    "- Only include users that have sent at least five tweets in the first few months of the year the data was collected (maybe not relevant for this data - the twitter bios data does not contain the tweets. Only creation date for the profile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "10.1thesis",
   "language": "python",
   "name": "10.1thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
