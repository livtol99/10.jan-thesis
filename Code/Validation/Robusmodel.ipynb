{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils2' from '/home/livtollanes/10.jan-thesis/Code/Validation/../Utility files/utils2.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from collections import Counter\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, GroupKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import spearmanr\n",
    "import matplotlib.lines as mlines\n",
    "# Local application imports\n",
    "sys.path.insert(0, '../Utility files')\n",
    "import utils2\n",
    "from utils2 import *\n",
    "\n",
    "from model_comparison import CrossValidation\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.robust.robust_linear_model import RLM\n",
    "import importlib\n",
    "importlib.reload(utils2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used file path: /home/livtollanes/NewData/job_title_coordinates/m1_jobs_rowcoords.csv\n",
      "Used file path: /home/livtollanes/NewData/job_title_coordinates/m2_jobs_rowcoords.csv\n",
      "Used file path: /home/livtollanes/NewData/job_title_coordinates/m3_jobs_rowcoords.csv\n",
      "Used file path: /home/livtollanes/NewData/job_title_coordinates/m4_jobs_rowcoords.csv\n",
      "Used file path: /home/livtollanes/NewData/job_title_coordinates/m5_jobs_rowcoords.csv\n",
      "Used file path: /home/livtollanes/NewData/job_title_coordinates/m6_jobs_rowcoords.csv\n",
      "Used file path: /home/livtollanes/NewData/job_title_coordinates/m7_jobs_rowcoords.csv\n",
      "Used file path: /home/livtollanes/NewData/job_title_coordinates/m8_jobs_rowcoords.csv\n",
      "Used file path: /home/livtollanes/NewData/job_title_coordinates/m9_jobs_rowcoords.csv\n",
      "Shape of dataframe 1: (11678, 14)\n",
      "Shape of dataframe 2: (11677, 14)\n",
      "Shape of dataframe 3: (10958, 14)\n",
      "Shape of dataframe 4: (10681, 14)\n",
      "Shape of dataframe 5: (10621, 14)\n",
      "Shape of dataframe 6: (10626, 14)\n",
      "Shape of dataframe 7: (3538, 14)\n",
      "Shape of dataframe 8: (11524, 14)\n",
      "Shape of dataframe 9: (4124, 14)\n"
     ]
    }
   ],
   "source": [
    "# Loading CA job coord files\n",
    "\n",
    "\n",
    "# Load the coordinate files for models 1 to 9\n",
    "dfs = utils2.load_CA_model_files(9)\n",
    "\n",
    "for i, df in enumerate(dfs):\n",
    "    print(f\"Shape of dataframe {i+1}: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:\n",
      "[-4.96630466e-05  6.67128015e-05  1.58902088e-05]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import HuberRegressor\n",
    "\n",
    "\n",
    "\n",
    "outcome = 'Salaire_moyen_en_EQTP'\n",
    "predictors = ['0', '1', '2']\n",
    "\n",
    "\n",
    "# Define your predictors and outcome\n",
    "X = dfs[0][predictors].values\n",
    "y = dfs[0][outcome].values\n",
    "\n",
    "# Create a HuberRegressor object\n",
    "huber = HuberRegressor(epsilon=1.35, max_iter=100, alpha=0.0001, warm_start=False, fit_intercept=True, tol=1e-05)\n",
    "\n",
    "# Fit the model\n",
    "huber.fit(X, y)\n",
    "\n",
    "# Print the coefficients\n",
    "print(\"Coefficients:\")\n",
    "print(huber.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              OLS Regression Results                             \n",
      "=================================================================================\n",
      "Dep. Variable:     Salaire_moyen_en_EQTP   R-squared:                       0.006\n",
      "Model:                               OLS   Adj. R-squared:                  0.005\n",
      "Method:                    Least Squares   F-statistic:                     21.27\n",
      "Date:                   Thu, 30 May 2024   Prob (F-statistic):           9.81e-14\n",
      "Time:                           09:44:29   Log-Likelihood:                -99560.\n",
      "No. Observations:                  11678   AIC:                         1.991e+05\n",
      "Df Residuals:                      11674   BIC:                         1.992e+05\n",
      "Df Model:                              3                                         \n",
      "Covariance Type:                     HC3                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       3697.3664     12.566    294.225      0.000    3672.734    3721.999\n",
      "0           -153.4984     19.836     -7.738      0.000    -192.380    -114.617\n",
      "1             91.7588     26.600      3.450      0.001      39.618     143.899\n",
      "2             31.1049     20.986      1.482      0.138     -10.031      72.240\n",
      "==============================================================================\n",
      "Omnibus:                     5117.322   Durbin-Watson:                   1.990\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            24807.925\n",
      "Skew:                           2.126   Prob(JB):                         0.00\n",
      "Kurtosis:                       8.737   Cond. No.                         2.30\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC3)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Assume dfs[0] is your DataFrame\n",
    "X = dfs[0][predictors]\n",
    "y = dfs[0][outcome]\n",
    "\n",
    "X = sm.add_constant(X)  # Add a constant column to include an intercept in the model\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# Get robust covariance results with HC3\n",
    "robust_results = results.get_robustcov_results(cov_type='HC3')\n",
    "\n",
    "print(robust_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for the first dataframe:\n",
      "                              WLS Regression Results                             \n",
      "=================================================================================\n",
      "Dep. Variable:     Salaire_moyen_en_EQTP   R-squared:                       0.110\n",
      "Model:                               WLS   Adj. R-squared:                  0.110\n",
      "Method:                    Least Squares   F-statistic:                     480.9\n",
      "Date:                   Thu, 30 May 2024   Prob (F-statistic):          1.25e-294\n",
      "Time:                           10:08:23   Log-Likelihood:                -88400.\n",
      "No. Observations:                  11678   AIC:                         1.768e+05\n",
      "Df Residuals:                      11674   BIC:                         1.768e+05\n",
      "Df Model:                              3                                         \n",
      "Covariance Type:               nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       3630.7507      3.369   1077.804      0.000    3624.148    3637.354\n",
      "0           -130.1895      4.470    -29.122      0.000    -138.952    -121.427\n",
      "1            111.8938      7.192     15.558      0.000      97.796     125.991\n",
      "2             15.8613      5.558      2.854      0.004       4.966      26.756\n",
      "==============================================================================\n",
      "Omnibus:                     2314.871   Durbin-Watson:                   1.970\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4552.156\n",
      "Skew:                           1.200   Prob(JB):                         0.00\n",
      "Kurtosis:                       4.896   Cond. No.                         5.28\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "WLS MSE: 1493650.6260961413\n",
      "WLS MAE: 652.9256758644315\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Define your predictors and outcome\n",
    "X = dfs[0][predictors]\n",
    "y = dfs[0][outcome]\n",
    "\n",
    "X = sm.add_constant(X)  # Add a constant column to include an intercept in the model\n",
    "\n",
    "# Initial OLS fit\n",
    "initial_model = sm.OLS(y, X)\n",
    "initial_results = initial_model.fit()\n",
    "\n",
    "# Calculate weights from residuals of initial fit\n",
    "weights = 1.0 / np.abs(initial_results.resid)\n",
    "\n",
    "# WLS fit with weights\n",
    "model = sm.WLS(y, X, weights=weights)\n",
    "results = model.fit()\n",
    "\n",
    "# Get robust covariance results with HC3\n",
    "robust_results = results.get_robustcov_results(cov_type='HC3')\n",
    "\n",
    "# Print the summary\n",
    "print(\"Summary for the first dataframe:\")\n",
    "print(results.summary())\n",
    "\n",
    "# Calculate the mean squared error and mean absolute error \n",
    "y_pred = results.predict(X)\n",
    "mse = mean_squared_error(y, y_pred) \n",
    "mae = mean_absolute_error(y, y_pred) \n",
    "\n",
    "print(\"WLS MSE:\", mse) \n",
    "print(\"WLS MAE:\", mae) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE after CV: 1496168.7597543069\n",
      "Average MAE after CV: 644.7494601645492\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Define your predictors and outcome\n",
    "X = dfs[0][predictors].values\n",
    "y = dfs[0][outcome].values\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for train, test in kfold.split(X, y):\n",
    "\n",
    "    X_train, X_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "\n",
    "    X_train = sm.add_constant(X_train)  # Add a constant column to include an intercept in the model\n",
    "\n",
    "    # Initial OLS fit\n",
    "    initial_model = sm.OLS(y_train, X_train)\n",
    "    initial_results = initial_model.fit()\n",
    "\n",
    "    # Calculate weights from residuals of initial fit\n",
    "    weights = 1.0 / np.abs(initial_results.resid)\n",
    "\n",
    "    # WLS fit with weights\n",
    "    model = sm.WLS(y_train, X_train, weights=weights)\n",
    "    results = model.fit()\n",
    "\n",
    "    # Get robust covariance results with HC3\n",
    "    robust_results = results.get_robustcov_results(cov_type='HC3')\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    X_test = sm.add_constant(X_test)\n",
    "    y_pred = results.predict(X_test)\n",
    "\n",
    "    # Calculate the mean squared error and mean absolute error \n",
    "    mse = mean_squared_error(y_test, y_pred) \n",
    "    mae = mean_absolute_error(y_test, y_pred) \n",
    "\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "\n",
    "print(\"Average MSE after CV:\", np.mean(mse_scores)) \n",
    "print(\"Average MAE after CV:\", np.mean(mae_scores)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for the full data fit:\n",
      "                            WLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.059\n",
      "Model:                            WLS   Adj. R-squared:                  0.059\n",
      "Method:                 Least Squares   F-statistic:                     222.3\n",
      "Date:                Thu, 30 May 2024   Prob (F-statistic):          6.46e-140\n",
      "Time:                        10:26:45   Log-Likelihood:                -80552.\n",
      "No. Observations:               10681   AIC:                         1.611e+05\n",
      "Df Residuals:                   10677   BIC:                         1.611e+05\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       3588.5386      2.989   1200.746      0.000    3582.680    3594.397\n",
      "x1           116.9452      4.615     25.338      0.000     107.898     125.992\n",
      "x2             9.6976      7.127      1.361      0.174      -4.272      23.667\n",
      "x3          -150.3363      7.622    -19.725      0.000    -165.276    -135.396\n",
      "==============================================================================\n",
      "Omnibus:                     1658.369   Durbin-Watson:                   1.986\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2704.439\n",
      "Skew:                           1.055   Prob(JB):                         0.00\n",
      "Kurtosis:                       4.276   Cond. No.                         3.45\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "R-squared for the full data fit: 0.05879690315542674\n",
      "RMSE for the full data fit: 1194.8980236864486\n",
      "MAE for the full data fit: 607.6530283470946\n",
      "Average RMSE after CV: 1194.7406299899042\n",
      "Average MAE after CV: 613.6397722357593\n",
      "Average R-squared after CV: -0.0006750147037444254\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Define your predictors and outcome\n",
    "X = dfs[3][predictors].values\n",
    "y = dfs[3][outcome].values\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "# Add a constant column to include an intercept in the model\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Initial OLS fit\n",
    "initial_model = sm.OLS(y, X)\n",
    "initial_results = initial_model.fit()\n",
    "\n",
    "# Calculate weights from residuals of initial fit\n",
    "weights = 1.0 / np.abs(initial_results.resid)\n",
    "\n",
    "# WLS fit with weights\n",
    "model = sm.WLS(y, X, weights=weights)\n",
    "results = model.fit()\n",
    "\n",
    "# Print the summary\n",
    "print(\"Summary for the full data fit:\")\n",
    "print(results.summary())\n",
    "\n",
    "# Calculate the R-squared for the full data fit\n",
    "print(\"R-squared for the full data fit:\", results.rsquared)\n",
    "\n",
    "# Calculate the RMSE and MAE for the full data fit\n",
    "y_pred = results.predict(X)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "mae = mean_absolute_error(y, y_pred)\n",
    "print(\"RMSE for the full data fit:\", np.sqrt(mse))\n",
    "print(\"MAE for the full data fit:\", mae)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for train, test in kf.split(X):\n",
    "\n",
    "    X_train, X_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "\n",
    "    # Initial OLS fit\n",
    "    initial_model = sm.OLS(y_train, X_train)\n",
    "    initial_results = initial_model.fit()\n",
    "\n",
    "    # Calculate weights from residuals of initial fit\n",
    "    weights = 1.0 / np.abs(initial_results.resid)\n",
    "\n",
    "    # WLS fit with weights\n",
    "    model = sm.WLS(y_train, X_train, weights=weights)\n",
    "    results = model.fit()\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = results.predict(X_test)\n",
    "\n",
    "    # Calculate the mean squared error, mean absolute error and R-squared\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "print(\"Average RMSE after CV:\", np.sqrt(np.mean(mse_scores)))\n",
    "print(\"Average MAE after CV:\", np.mean(mae_scores))\n",
    "print(\"Average R-squared after CV:\", np.mean(r2_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "09.2thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
